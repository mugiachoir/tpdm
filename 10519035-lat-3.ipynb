{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regresion\n",
      "Akurasi =  0.8791500664010624\n",
      "Matrix Confussion\n",
      "[[477   1  74]\n",
      " [  1 164  19]\n",
      " [ 72  15 683]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.86      0.87       552\n",
      "           2       0.91      0.89      0.90       184\n",
      "           3       0.88      0.89      0.88       770\n",
      "\n",
      "    accuracy                           0.88      1506\n",
      "   macro avg       0.89      0.88      0.88      1506\n",
      "weighted avg       0.88      0.88      0.88      1506\n",
      "\n",
      "K-Neighborhood \n",
      "Akurasi =  0.8247011952191236\n",
      "Matrix Confussion\n",
      "[[442  22  88]\n",
      " [  1 172  11]\n",
      " [116  26 628]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.80      0.80       552\n",
      "           2       0.78      0.93      0.85       184\n",
      "           3       0.86      0.82      0.84       770\n",
      "\n",
      "    accuracy                           0.82      1506\n",
      "   macro avg       0.81      0.85      0.83      1506\n",
      "weighted avg       0.83      0.82      0.82      1506\n",
      "\n",
      "Decision Tree\n",
      "Akurasi =  0.8087649402390438\n",
      "Matrix Confussion\n",
      "[[416   3 133]\n",
      " [  1 174   9]\n",
      " [134   8 628]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.75      0.75       552\n",
      "           2       0.94      0.95      0.94       184\n",
      "           3       0.82      0.82      0.82       770\n",
      "\n",
      "    accuracy                           0.81      1506\n",
      "   macro avg       0.84      0.84      0.84      1506\n",
      "weighted avg       0.81      0.81      0.81      1506\n",
      "\n",
      "Prediksi dengan Logistic Regression =  Keluhan\n",
      "Prediksi dengan K-Nearest Neighborhood = Keluhan\n",
      "Prediksi dengan Decision Tree =  Keluhan\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd \n",
    "\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "#-------------------------------------------------------------\n",
    "#Reading file from \\Tweet.csv\\\n",
    "def baca_file():\n",
    "\n",
    "    csvF1 = 'Tweet.csv'\n",
    "# TAMBAHKAN ENCODING karena utf-8 error coba latin1\n",
    "    #Open file Tweet.csv to manipulate  \n",
    "    with open(csvF1,\"r\",encoding='latin1') as rCsv:\n",
    "        readCsv = csv.reader(rCsv, delimiter = ';')\n",
    "        read = []\n",
    "        for row in readCsv:\n",
    "            if len(row) != 0:\n",
    "                read = read + [row]\n",
    "\n",
    "    rCsv.close()\n",
    "    return(read)\n",
    "\n",
    "    #--------------------------------------------------------------\n",
    "    #Procedure for displaying the result to the console\n",
    "def tampil_csv(f2):\n",
    "    df3 = pd.DataFrame(f2)\n",
    "    print(df3)\n",
    "\n",
    "    #--------------------------------------------------------------  \n",
    "    #Function stemming and return the value of feature and target\n",
    "def stemmingFile(fCsv):\n",
    "\n",
    "    #---Define a new list for temporary reading---#\n",
    "    rList = []\n",
    "    eList =[]\n",
    "    \n",
    "    #---initialization a stopword by Sastrawi---#\n",
    "    facto  = StopWordRemoverFactory()\n",
    "    stopwords = facto.create_stop_word_remover()\n",
    "\n",
    "    #---Looping to read line by line csv file---#  \n",
    "    for idx in fCsv:\n",
    "        rList.append(stopwords.remove(idx[0]))\n",
    "\n",
    "        #---change every word in target to new value---#\n",
    "        if idx[1] == 'Keluhan':\n",
    "            eList.append('1')\n",
    "        elif idx[1]== 'Respon':\n",
    "            eList.append('2')\n",
    "        else:\n",
    "            eList.append('3')\n",
    "        #--- end of IF ---#\n",
    "\n",
    "        #--- end of looping ---#\n",
    "    return (rList,eList)#parameter return\n",
    "\n",
    "    #-------------------------------------------------------------\n",
    "    #procedure to classify every sample in Tweeter.csv\n",
    "def classiLogRegressi(lRead, rRead):\n",
    "\n",
    "    #---setting validation 20% fromm data sample---#\n",
    "    validation_size = 0.20\n",
    "    seed = 7\n",
    "    X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(lRead, rRead, test_size=validation_size, random_state=seed)\n",
    "\n",
    "    #---TF-IDF vectorizer, collecting value into vector---#\n",
    "    w = TfidfVectorizer()\n",
    "\n",
    "    print('Logistic Regresion')\n",
    "    logistic = LogisticRegression()\n",
    "    logistic = Pipeline([\n",
    "    ('xPipe',w),\n",
    "    ('knn', logistic)])\n",
    "\n",
    "    logistic.fit(X_train, Y_train)\n",
    "    predictions = logistic.predict(X_validation)\n",
    "\n",
    "    print('Akurasi = ', accuracy_score(Y_validation, predictions))\n",
    "    print('Matrix Confussion')\n",
    "    print(confusion_matrix(Y_validation, predictions))\n",
    "    print(classification_report(Y_validation, predictions))\n",
    "\n",
    "    return(logistic)\n",
    "\n",
    "    #------------------------------------------------------------\n",
    "def classKNeighborsClassifier(lRead, rRead):\n",
    "\n",
    "    #---setting validation 20% fromm data sample---#\n",
    "    validation_size = 0.20\n",
    "    seed = 7\n",
    "    X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(lRead, rRead, test_size=validation_size, random_state=seed)\n",
    "\n",
    "    #---TF-IDF vectorizer, collecting value into vector---#\n",
    "    w = TfidfVectorizer()\n",
    "    #   \n",
    "    #---classification using K-NN---# \n",
    "    print('K-Neighborhood ')\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn = Pipeline([\n",
    "    ('xPipe',w),\n",
    "    ('knn', knn)])\n",
    "\n",
    "    knn.fit(X_train, Y_train)\n",
    "    predictions = knn.predict(X_validation)\n",
    "    print('Akurasi = ', accuracy_score(Y_validation, predictions))\n",
    "    print('Matrix Confussion')\n",
    "    print(confusion_matrix(Y_validation, predictions))\n",
    "    print(classification_report(Y_validation, predictions))\n",
    "\n",
    "    return(knn)\n",
    "\n",
    "    #-------------------------------------------------------------\n",
    "def classDecisionTree(lRead, rRead):\n",
    "\n",
    "    #---setting validation 20% fromm data sample---#\n",
    "    validation_size = 0.20\n",
    "    seed = 7\n",
    "    X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(lRead, rRead, test_size=validation_size, random_state=seed)\n",
    "\n",
    "    #---TF-IDF vectorizer, collecting value into vector---#\n",
    "    w = TfidfVectorizer()\n",
    "    #   \n",
    "    #---classification using K-NN---# \n",
    "    print('Decision Tree')\n",
    "    deTree = DecisionTreeClassifier()\n",
    "    deTree = Pipeline([\n",
    "    ('xPipe',w),\n",
    "    ('knn', deTree)])\n",
    "\n",
    "    deTree.fit(X_train, Y_train)\n",
    "    predictions = deTree.predict(X_validation)\n",
    "    print('Akurasi = ', accuracy_score(Y_validation, predictions))\n",
    "    print('Matrix Confussion')\n",
    "    print(confusion_matrix(Y_validation, predictions))\n",
    "    print(classification_report(Y_validation, predictions))\n",
    "\n",
    "    return(deTree)\n",
    "\n",
    "\n",
    "    #----------------------------------------------------------------\n",
    "def singleTextLogisticRegression(xText, mknn):   \n",
    "\n",
    "    x_test =[]\n",
    "    x_test.append(xText)\n",
    "    mpredictions = mknn.predict(x_test)\n",
    "\n",
    "    return(mpredictions)\n",
    "\n",
    "    #----------------------------------------------------------------\n",
    "\n",
    "def singleTextKNeighbor(xText, cKboar):   \n",
    "\n",
    "    x_test =[]\n",
    "    x_test.append(xText)\n",
    "    mpredictions = cKboar.predict(x_test)\n",
    "\n",
    "    return(mpredictions)\n",
    "\n",
    "    #-----------------------------------------------------------------\n",
    "\n",
    "def singleTextDecisionTree(xText, dTree):   \n",
    "\n",
    "    x_test =[]\n",
    "    x_test.append(xText)\n",
    "    mpredictions = dTree.predict(x_test)\n",
    "\n",
    "    return(mpredictions)\n",
    "\n",
    "    #-----------------------------------------------------------------\n",
    "def singleTextNaiveBayes(xText, mBayes):   \n",
    "\n",
    "    x_test =[]\n",
    "    x_test.append(xText)\n",
    "    mpredictions = mBayes.predict(x_test)\n",
    "\n",
    "    return(mpredictions)\n",
    "    #-----------------------------------------------------------------\n",
    "\n",
    "def konversiPrediksi(pre):\n",
    "    tulis = ''\n",
    "    if pre == '1':\n",
    "        tulis = 'Keluhan'\n",
    "    elif pre== '2':\n",
    "        tulis = 'Respon'\n",
    "    else:\n",
    "        tulis = 'Not Keluhan/Respon' \n",
    "\n",
    "    return(tulis) \n",
    "\n",
    "#-----Program utama----------------------------------------------- \n",
    "if __name__ == '__main__': \n",
    "\n",
    "    dList, fList = stemmingFile(baca_file())\n",
    "\n",
    "    #---model logistic regression---\n",
    "\n",
    "    logRes   = classiLogRegressi(dList, fList)\n",
    "    Neighbor = classKNeighborsClassifier(dList, fList)\n",
    "    DesTree  = classDecisionTree(dList, fList)  \n",
    "\n",
    "\n",
    "    testing = input('Masukkan text tweet = ')\n",
    "\n",
    "    l = singleTextLogisticRegression(testing, logRes)\n",
    "\n",
    "    k = singleTextKNeighbor(testing, Neighbor)\n",
    "\n",
    "    t = singleTextDecisionTree(testing, DesTree)\n",
    "\n",
    "\n",
    "    print('Prediksi dengan Logistic Regression = ',konversiPrediksi(l))\n",
    "    print('Prediksi dengan K-Nearest Neighborhood =',konversiPrediksi(k))\n",
    "    print('Prediksi dengan Decision Tree = ', konversiPrediksi(t))\n",
    "#----End of Program-------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9c1d5a056f04d97314a9f946bc8c5185004572d3d68312220c0ba298420421f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
